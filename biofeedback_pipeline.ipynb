{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bio-Feedback Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Code to train model with old data before experiment (only do once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Define the Kalman Filter Function\n",
    "def kalman(measurement_list, process_noise, variance, pipeline, files=None):\n",
    "    \"\"\"Kalman filter\n",
    "    Args:\n",
    "        measurement_list ([float]): A time-ordered series of environmental estimates\n",
    "        process_noise (float): Approximate process noise for the estimation process.\n",
    "        variance (float or [float]): Either a single value (for static variance)\n",
    "            or a list of values (for dynamic variance)\n",
    "    Returns:\n",
    "        [float]: Kalman filtered estimate buffer\n",
    "    \"\"\"\n",
    "    if len(measurement_list) <= 1:\n",
    "        return measurement_list\n",
    "    dyn_variance = type(variance) is not float\n",
    "    estimate_buffer = []\n",
    "    if 'Speed' in pipeline:\n",
    "        prior_estimate = 0.6\n",
    "        prior_variance = 0.2 if dyn_variance else variance\n",
    "    elif 'Slope' in pipeline:\n",
    "        prior_estimate = 10\n",
    "        prior_variance = 1 if dyn_variance else variance\n",
    "    elif 'Height' in pipeline:\n",
    "        prior_estimate = 15\n",
    "        prior_variance = 1.2 if dyn_variance else variance\n",
    "\n",
    "    for i in range(len(measurement_list)):\n",
    "        if files is None or files[i] == files[i - 1]:\n",
    "            # Zn Measurements\n",
    "            single_measurement = measurement_list[i]\n",
    "            #single_variance = abs(variance[i]) if dyn_variance else variance\n",
    "            single_variance = variance\n",
    "            # Update\n",
    "            k_gain = prior_variance / (prior_variance + single_variance)\n",
    "            if estimate_buffer:\n",
    "                estimate = estimate_buffer[i - 1] + k_gain * (single_measurement - estimate_buffer[i - 1])\n",
    "            else:\n",
    "                estimate = prior_estimate + k_gain * (single_measurement - prior_estimate)\n",
    "            estimate_buffer.append(estimate)\n",
    "\n",
    "            # Update Variance\n",
    "            prior_variance = (1 - k_gain) * prior_variance + process_noise\n",
    "        else:\n",
    "            estimate_buffer.append(measurement_list[i])\n",
    "            #prior_variance = abs(variance[i]) if dyn_variance else variance\n",
    "            prior_variance = variance\n",
    "    return np.array(estimate_buffer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_table_names = []\n",
    "peak_values = []; #This initializes the peak torque values matrix for later use\n",
    "\n",
    "# Desired channels to train with \n",
    "col_names = ['right_FP_x', 'right_FP_y', 'right_FP_z', \n",
    "          'left_FP_x', 'left_FP_y', 'left_FP_z', \n",
    "          'shank_acc_x', 'shank_acc_y', 'shank_acc_z', 'shank_gyro_x', 'shank_gyro_y', 'shank_gyro_z' ,\n",
    "          'foot_acc_x', 'foot_acc_y', 'foot_acc_z', 'foot_gyro_x', 'foot_gyro_y', 'foot_gyro_z', \n",
    "          'thigh_acc_x', 'thigh_acc_y', 'thigh_acc_z', 'thigh_gyro_x', 'thigh_gyro_y', 'thigh_gyro_z', \n",
    "          'torso_acc_x', 'torso_acc_y', 'torso_acc_z', 'torso_gyro_x', 'torso_gyro_y', 'torso_gyro_z',]\n",
    "#col_names = ['shank_acc_x', 'shank_acc_y', 'shank_acc_z', 'shank_gyro_x', 'shank_gyro_y', 'shank_gyro_z' ,\n",
    "#           'foot_acc_x', 'foot_acc_y', 'foot_acc_z', 'foot_gyro_x', 'foot_gyro_y', 'foot_gyro_z', \n",
    "#           'thigh_acc_x', 'thigh_acc_y', 'thigh_acc_z', 'thigh_gyro_x', 'thigh_gyro_y', 'thigh_gyro_z', \n",
    "#          'torso_acc_x', 'torso_acc_y', 'torso_acc_z', 'torso_gyro_x', 'torso_gyro_y', 'torso_gyro_z'\n",
    "#          ]\n",
    "#col_names = ['right_FP_x', 'right_FP_y', 'right_FP_z', \n",
    "#           'left_FP_x', 'left_FP_y', 'left_FP_z',\n",
    "#            'thigh_acc_x', 'thigh_acc_y', 'thigh_acc_z', 'thigh_gyro_x', 'thigh_gyro_y', 'thigh_gyro_z']\n",
    "col_feat = ['min_','max_', 'mean_', 'std_', 'end_']\n",
    "\n",
    "\n",
    "#feature_table_length = col_names*col_feat\n",
    "\n",
    "for i in range(len(col_names)):\n",
    "    for j in range(len(col_feat)):\n",
    "    \n",
    "        \n",
    "        feature_table_names.append(col_feat[j]+col_names[i])\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "#Create labels for ground truth labels\n",
    "ground_truth_names = ['hip_torque','knee_torque', 'L5_S1_flex_torque']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# subjects used for training the model\n",
    "subject_num = ['04', '05', '06', '07', '09','10','15']\n",
    "lift_type = 'KW' #Lift type\n",
    "degree = 0 #Degree of lift\n",
    "lift_side = 'R' #Side the lift starts on\n",
    "side = lift_side #These two variables are the same thing\n",
    "\n",
    "#IF TRAINING ON ALL THE SUBJECT, SET test_sub T0 '100'\n",
    "c = 0 #Index of the test subject in subarray\n",
    "test_sub = subject_num[c]\n",
    "#test_sub = '100'\n",
    "\n",
    "data_train = pd.DataFrame()\n",
    "\n",
    "start_i = 0\n",
    "\n",
    "\n",
    "# add all data across subjects and trial to data_train\n",
    "for j in range(start_i,len(subject_num)):\n",
    "    #Does not add test_sub to training set if test_sub exists\n",
    "    if subject_num[j] == test_sub:\n",
    "                message = \"--- Subject \"+str(subject_num[j])+\" is test Trial --- \"\n",
    "                print('---------------')\n",
    "                print(message)\n",
    "                print('---------------')\n",
    "    else:\n",
    "        for i in range(1,8):\n",
    "\n",
    "                message = \"--- Adding Subject \"+ str(subject_num[j]) + \" Trial \" +str(i)+\"  to the training data ---\"\n",
    "                print(message)\n",
    "                if degree == 0:\n",
    "                    file = \"feature_tables/100_ms_window_20_ms_increment/DOE_Biomech_\"+str(subject_num[j])+\"_L_\"+str(degree)+\"_\"+lift_type+\"_0\"+str(i)+\".csv\"\n",
    "                else:\n",
    "                    file = \"feature_tables/100_ms_window_20_ms_increment/DOE_Biomech_\"+str(subject_num[j])+\"_L_\"+str(degree)+\"_\"+lift_side+\"_\"+lift_type+\"_0\"+str(i)+\".csv\"\n",
    "                print(file)\n",
    "                data = pd.read_csv(file)\n",
    "                print(\"Data Row: \"+str(data.shape[0]))\n",
    "                data_train = pd.concat([data_train,data],ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Train Trials:')\n",
    "print(data_train.info())\n",
    "\n",
    "#Seperate the training set features and labels\n",
    "x_train = data_train[feature_table_names]\n",
    "y_train = data_train[ground_truth_names]\n",
    "\n",
    "print('Train Trials:')\n",
    "print(x_train.info())\n",
    "\n",
    "#Scale the data\n",
    "sc=StandardScaler()\n",
    "\n",
    "scaler = sc.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "\n",
    "# Create Models\n",
    "\n",
    "\n",
    "model_L5S1 = XGBRegressor()\n",
    "\n",
    "kernel_size = 10\n",
    "kernel = np.ones(kernel_size) / kernel_size\n",
    "GT_lumbar_torque = y_train.L5_S1_flex_torque\n",
    "data_convolved = np.convolve(GT_lumbar_torque, kernel, mode='same')\n",
    "\n",
    "model_L5S1.fit(x_train_scaled,data_convolved)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start matlab engine (only run this once) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matlab.engine\n",
    "\n",
    "eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The next part of the Pipeline Needs to be Run after Trial\n",
    "\n",
    "### 1. It reads the c3d file that vicon creates and then build the feature tables\n",
    "### 2. It predicts the lumbar bio-torque from the model creates above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next block is used to determine the file that needs to be read. It should be updated after each trial so that it reads the most recent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = '04'\n",
    "trial = '02'\n",
    "\n",
    "#Should be the same conidtons as the trained values\n",
    "#degree = 180\n",
    "#side = 'R'\n",
    "#lift_type = 'KW'\n",
    "\n",
    "\n",
    "weight_kg = 66.9582 #Sub 4 mass\n",
    "#weight_kg = 90.9117 #sub 5 mass\n",
    "#weight_kg = 60.2836 #Sub 6 mass\n",
    "#weight_kg = 86.882 #sub 7 mass\n",
    "#weight_kg = 89.48 #Sub 9 mass\n",
    "#weight_kg = 66.8298 #sub 10 mass\n",
    "#weight_kg = 85.494 #Sub 15 mass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next block makes a prediction of the lumbar bio-torque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if degree == 0:\n",
    "    c3dFilePath = \"D:\\\\Dropbox (Gatech)\\\\DOE_Exos\\\\Experiments\\\\DOE Biomechanics\\\\DOE_Biomech_\"+subject+\"_PROCESSED\\\\New Session\\\\DOE_Biomech_\"+subject+\"_L_\"+str(degree)+\"_\"+lift_type+\"_\"+trial+\"_filled.c3d\"\n",
    "else:\n",
    "    c3dFilePath = \"D:\\\\Dropbox (Gatech)\\\\DOE_Exos\\\\Experiments\\\\DOE Biomechanics\\\\DOE_Biomech_\"+subject+\"_PROCESSED\\\\New Session\\\\DOE_Biomech_\"+subject+\"_L_\"+str(degree)+\"_\"+side+\"_\"+lift_type+\"_\"+trial+\"_filled.c3d\"\n",
    "    \n",
    "print(c3dFilePath)\n",
    "results_features, labels_features = eng.generate_feature_tables(c3dFilePath, degree)\n",
    "df_features = pd.DataFrame(results_features,columns=labels_features)\n",
    "\n",
    "x_test = df_features[feature_table_names]\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "y_pred_back =  model_L5S1.predict(x_test_scaled)\n",
    "\n",
    "\n",
    "\n",
    "process_noise = 0.1\n",
    "variance = np.var(y_pred_back)\n",
    "#print(variance)\n",
    "pipeline = 'Speed'\n",
    "\n",
    "ML_pred_filtered = kalman(y_pred_back, process_noise, variance,pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have matlab plot out the predicted peak torque of the lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torque_data = ML_pred_filtered*weight_kg\n",
    "\n",
    "\n",
    "peak_torque= max(torque_data)\n",
    "peak_values = np.append(peak_values,peak_torque)\n",
    "print(peak_values)\n",
    "finished = eng.plot_torque_info(torque_data.tolist(), peak_values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear the peak values so that it does not keep plotting old peak data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(peak_values)\n",
    "peak_values = np.array([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next block is used to plot the prediction. This is making a prediction of bio-torque that we already know so it is plotted vs the ground truth (this will not be possible in the actual experiments because we will not know ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window_increment = 0.02\n",
    "start_time = 0.1\n",
    "\n",
    "time = np.arange(start_time, len(ML_pred_filtered)*window_increment+start_time, window_increment)\n",
    "plt.plot(time, ML_pred_filtered, label='Predicted Torque')\n",
    "\n",
    "#read ground truth torques\n",
    "if degree == 0:\n",
    "    torques_file = 'ground_truth\\\\DOE_Biomech_'+subject+'_L_'+str(degree)+'_'+lift_type+'_'+trial+'_ID.sto'\n",
    "else:\n",
    "    torques_file = 'ground_truth\\\\DOE_Biomech_'+subject+'_L_'+str(degree)+'_'+side+'_'+lift_type+'_'+trial+'_ID.sto'\n",
    "    \n",
    "print(torques_file)   \n",
    "data,column_names = eng.readSTO(torques_file)\n",
    "df_torque = pd.DataFrame(data, columns = column_names)\n",
    "#print(df_torque['time'])\n",
    "#print(df_torque['L5_S1_Flex_Ext_moment'])\n",
    "#weight_kg = 66.9582 #Sub 4 mass\n",
    "#weight_kg = 90.9117 #sub 5 mass\n",
    "#weight_kg = 60.2836 #Sub 6 mass\n",
    "#weight_kg = 86.882 #sub 7 mass\n",
    "#weight_kg = 89.48 #Sub 9 mass\n",
    "#weight_kg = 66.8298 #sub 10 mass\n",
    "#weight_kg = 85.494 #Sub 15 mass\n",
    "\n",
    "\n",
    "kernel_size = 20\n",
    "kernel = np.ones(kernel_size) / kernel_size\n",
    "GT_lumbar_torque = df_torque['L5_S1_Flex_Ext_moment']\n",
    "data_convolved = np.convolve(GT_lumbar_torque, kernel, mode='same')\n",
    "\n",
    "\n",
    "plt.plot(df_torque['time'], data_convolved/weight_kg, label = 'Ground Truth Torque')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('time[ms]')\n",
    "plt.ylabel('Torque (N-m/kg)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This cell stops the Matlab Engine (Run this at the end of each experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Matlab Engine\n",
    "eng.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
